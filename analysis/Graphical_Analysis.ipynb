{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# GRAPHICAL ANALYSIS OF THE TeFE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepping up"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import pickle\n",
    "from pyspark.sql import SparkSession\n",
    "import json\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from operator import add\n",
    "import kaleido\n",
    "import plotly.io as pio"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def load_into_df(_file):\n",
    "    if 'pkl' in _file:\n",
    "        with open(_file, 'rb') as f:\n",
    "            df = pickle.load(f)\n",
    "    elif 'csv' in _file:\n",
    "        df = pd.read_csv (_file)\n",
    "    elif 'feather' in _file:\n",
    "        df = pd.read_feather(_file)\n",
    "    elif 'parquet' in _file:\n",
    "        df = pd.read_parquet(_file)\n",
    "    else:\n",
    "        print('not loaded, format unsupported')\n",
    "        df = pd.DataFrame(['Not loaded', 'format unsupported'])\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 128. KiB for an array with shape (16384,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-50e3dddcd5b4>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mmix_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_into_df\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'normal_mix____ALL_NO_NO.csv'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mcontracts_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_into_df\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'normal_contracts____ALL_NO_NO.csv'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mtechnologic_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_into_df\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'normal_technologic____ALL_NO_NO.csv'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0magents_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_into_df\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'normal_agents____ALL_NO_NO.csv'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-2-ae04292cb59f>\u001B[0m in \u001B[0;36mload_into_df\u001B[1;34m(_file)\u001B[0m\n\u001B[0;32m      4\u001B[0m             \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpickle\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[1;34m'csv'\u001B[0m \u001B[1;32min\u001B[0m \u001B[0m_file\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m         \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0m_file\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[1;34m'feather'\u001B[0m \u001B[1;32min\u001B[0m \u001B[0m_file\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m         \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_feather\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_file\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m                 )\n\u001B[1;32m--> 311\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    678\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    679\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 680\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    681\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    682\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    579\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    580\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mparser\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 581\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mparser\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    582\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    583\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m   1252\u001B[0m             \u001B[0mnrows\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalidate_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"nrows\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1253\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1254\u001B[1;33m                 \u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcol_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1255\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1256\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001B[0m in \u001B[0;36mread\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m    223\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    224\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlow_memory\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 225\u001B[1;33m                 \u001B[0mchunks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_low_memory\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    226\u001B[0m                 \u001B[1;31m# destructive to chunks\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    227\u001B[0m                 \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_concatenate_chunks\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mchunks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers._try_int64\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 128. KiB for an array with shape (16384,) and data type int64"
     ]
    }
   ],
   "source": [
    "mix_df = load_into_df('normal_mix____ALL_NO_NO.csv')\n",
    "contracts_df = load_into_df('normal_contracts____ALL_NO_NO.csv')\n",
    "technologic_df = load_into_df('normal_technologic____ALL_NO_NO.csv')\n",
    "agents_df = load_into_df('normal_agents____ALL_NO_NO.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('lines, ', mix_df.shape[0])\n",
    "print('columns, ', mix_df.shape[1])\n",
    "columns_mix_df = list(mix_df[:])\n",
    "print('columns are:', columns_mix_df)\n",
    "print('Number of unique rows:', len(mix_df.entry.unique()))\n",
    "mix_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mix_df.groupby(['period', 'seed'],as_index=False)['Lumps'].sum().groupby(['period'], as_index=False).quantile(0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('lines, ', agents_df.shape[0])\n",
    "print('columns, ', agents_df.shape[1])\n",
    "columns_agents_df = list(agents_df[:])\n",
    "print('columns are:', columns_agents_df)\n",
    "print('Number of unique rows:', len(agents_df.entry.unique()))\n",
    "agents_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('lines, ', contracts_df.shape[0])\n",
    "print('columns, ', contracts_df.shape[1])\n",
    "columns_contracts_df = list(contracts_df[:])\n",
    "print('columns are:', columns_contracts_df)\n",
    "print('Number of unique rows:', len(contracts_df.entry.unique()))\n",
    "contracts_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('lines, ', technologic_df.shape[0])\n",
    "print('columns, ', technologic_df.shape[1])\n",
    "columns_technologic_df = list(technologic_df[:])\n",
    "print('columns are:', columns_technologic_df)\n",
    "print('Number of unique rows:', len(technologic_df.entry.unique()))\n",
    "technologic_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_period = mix_df.period.max()\n",
    "min_period = mix_df.period.min()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "main_agents_df_median = agents_df.groupby([\"period\", 'genre'], as_index=False)[columns_agents_df].median()\n",
    "print(main_agents_df_median.head())\n",
    "\n",
    "main_agents_df_mean = agents_df.groupby([\"period\", 'genre'], as_index=False)[columns_agents_df].mean()\n",
    "print(main_agents_df_mean.head())\n",
    "\n",
    "main_agents_df_25quart = agents_df.groupby([\"period\", 'genre'], as_index=False)[columns_agents_df].quantile(.25)\n",
    "print(main_agents_df_25quart.head())\n",
    "\n",
    "main_agents_df_75quart = agents_df.groupby([\"period\", 'genre'], as_index=False)[columns_agents_df].quantile(.75)\n",
    "main_agents_df_75quart.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agents_df.groupby(['period'], as_index=False).max()['period'][ : : -1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def iqr_plotly(var, dataframe, x_axis, groupby=None, remove_outliers=True, _sum=False, _old=False):\n",
    "\n",
    "    if groupby is None:\n",
    "        groupby = [x_axis]\n",
    "\n",
    "    # var = 'capacity'\n",
    "    # name_o_var = 'Number of adaptations'\n",
    "\n",
    "    # .groupby(['period', 'seed'],as_index=False)['Lumps'].sum().groupby(['period'], as_index=False).quantile(0.5)\n",
    "\n",
    "    x =     list(dataframe.groupby([x_axis], as_index=False).max()[x_axis])\n",
    "    x_rev = list(dataframe.groupby([x_axis], as_index=False).max()[x_axis][ : : -1])\n",
    "\n",
    "    if _sum is True or _old is True:\n",
    "        DF = dataframe.groupby(['period', 'seed'],as_index=False)[var].sum() if _sum is True else dataframe.groupby(['period', 'seed'],as_index=False)[var].mean()\n",
    "\n",
    "        _y_max=  list(DF.groupby(groupby, as_index=False).quantile(1)[var])\n",
    "        y_upper= list(DF.groupby(groupby, as_index=False).quantile(.75)[var])\n",
    "        y_median=list(DF.groupby(groupby, as_index=False).median()     [var])\n",
    "        y_mean=  list(DF.groupby(groupby, as_index=False).mean()       [var])\n",
    "        y_bottom=list(DF.groupby(groupby, as_index=False).quantile(.25)[var])\n",
    "        _y_min=  list(DF.groupby(groupby, as_index=False).quantile(0)[var])\n",
    "\n",
    "    else:\n",
    "\n",
    "        _y_max=  list(dataframe.groupby(['period', 'seed'],as_index=False)[var].quantile(1).groupby(['period'], as_index=False)  .mean()[var])\n",
    "        y_upper= list(dataframe.groupby(['period', 'seed'],as_index=False)[var].quantile(.75).groupby(['period'], as_index=False) .mean()[var])\n",
    "        y_median=list(dataframe.groupby(['period', 'seed'],as_index=False)[var].median().groupby(['period'], as_index=False).mean()[var])\n",
    "        y_mean=  list(dataframe.groupby(['period', 'seed'],as_index=False)[var].mean().groupby(['period'], as_index=False)  .mean()[var])\n",
    "        y_bottom=list(dataframe.groupby(['period', 'seed'],as_index=False)[var].quantile(.25).groupby(['period'], as_index=False).mean()[var])\n",
    "        _y_min=  list(dataframe.groupby(['period', 'seed'],as_index=False)[var].quantile(0).groupby(['period'], as_index=False)  .mean()[var])\n",
    "\n",
    "    if remove_outliers is True:\n",
    "        y_max = []\n",
    "        y_min = []\n",
    "        for i in range(0,len(_y_max)):\n",
    "            y_max.append(min(max(_y_max[i], y_upper[i], y_median[i], y_bottom[i], _y_min[i]), y_upper[i] + 1.5*(y_upper[i]-y_bottom[i])))\n",
    "            y_min.append(max(min(_y_max[i], y_upper[i], y_median[i], y_bottom[i], _y_min[i]), y_bottom[i] - 1.5*(y_upper[i]-y_bottom[i])))\n",
    "    else:\n",
    "        y_max = _y_max\n",
    "        y_min = _y_min\n",
    "\n",
    "    y_min = y_min[: : -1]\n",
    "    y_bottom=y_bottom[: : -1]\n",
    "\n",
    "    return x, x_rev, y_upper, y_median, y_mean, y_bottom, y_max, y_min"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def simple_graph(name_o_var, var, dataframe, x_axis, groupby=None, remove_outliers=True, show=True, log_y=False, log_x=False, color='232,126,4', _sum=False):\n",
    "\n",
    "    x, x_rev, y_upper, y_median, y_mean, y_bottom, y_max, y_min = iqr_plotly(var, dataframe, x_axis, groupby, remove_outliers, _sum=_sum)\n",
    "\n",
    "    fig = go.Figure(go.Scatter(name=\"IQR (%s)\" % name_o_var,\n",
    "                             x=x + x_rev,\n",
    "                             y=y_upper+y_bottom,\n",
    "                             fill='toself',\n",
    "                             fillcolor='rgba(%s,0.4)' % color,\n",
    "                             line=dict(color='rgba(255,255,255,0)')))\n",
    "\n",
    "    fig.add_trace(go.Scatter(name=\"Max and min (%s)\" % name_o_var,\n",
    "                             x=x + x_rev,\n",
    "                             y=y_max+y_min,\n",
    "                             fill='toself',\n",
    "                             fillcolor='rgba(%s,0.2)' % color,\n",
    "                             line=dict(color='rgba(255,255,255,0)')))\n",
    "\n",
    "    fig.add_trace(go.Scatter(name=\"Median (%s)\" % name_o_var,\n",
    "                             x=x + x_rev,\n",
    "                             y=y_median,\n",
    "                            mode='lines',\n",
    "                             line=dict(color='rgba(%s,1)' % color, dash='dot')))\n",
    "\n",
    "    fig.update_yaxes(type=\"log\") if log_y is True else None\n",
    "    fig.update_xaxes(type=\"log\") if log_x is True else None\n",
    "    fig.update_layout(barmode='overlay', template=\"simple_white\")\n",
    "\n",
    "    title=str(name_o_var) + ' over ' + str(x_axis)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=str(x_axis),\n",
    "        yaxis_title=str(name_o_var),\n",
    "        barmode='overlay',\n",
    "        template=\"simple_white\")\n",
    "\n",
    "    # fig.show()\n",
    "\n",
    "    file_name = title + \".html\"\n",
    "    pathfile='Figures/'\n",
    "\n",
    "    fig.write_html(pathfile + file_name)\n",
    "\n",
    "    return fig.show() if show is True else None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "color=('232,126,4')\n",
    "print('%s' % color)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "name_o_var = 'LSS_tot'\n",
    "\n",
    "dataframe = agents_df  # .loc[agents_df['genre'] == 'TP']\n",
    "\n",
    "x, x_rev, y_upper, y_median, y_mean, y_bottom, y_max, y_min = iqr_plotly('LSS_tot', dataframe, 'period', remove_outliers=True, _sum=True)\n",
    "\n",
    "fig = go.Figure(go.Scatter(name=\"IQR (%s)\" % name_o_var,\n",
    "                             x=x + x_rev,\n",
    "                             y=list(y_upper) + list(y_bottom),\n",
    "                             fill='toself',\n",
    "                             fillcolor='rgba(232,126,4,0.2)',\n",
    "                             line=dict(color='rgba(255,255,255,0)')))\n",
    "\n",
    "fig.add_trace(go.Scatter(name=\"Max and min (%s)\" % name_o_var, x=x + x_rev,\n",
    "                         y=list(y_max) + list(y_min), fill='toself', fillcolor='rgba(232,126,4,0.4)', line=dict(color='rgba(255,255,255,0)')))\n",
    "\n",
    "fig.add_trace(go.Scatter(name=\"Median (%s)\" % name_o_var,\n",
    "                             x= x,\n",
    "                             y=y_median,\n",
    "                         mode='lines',\n",
    "                             line=dict(color='rgba(232,126,4,1)', dash='dot')))\n",
    "\n",
    "\n",
    "fig.update_layout(barmode='overlay', template=\"simple_white\")\n",
    "fig.show()\n",
    "\n",
    "file_name = str(name_o_var) + \".html\"\n",
    "pathfile='Figures/'\n",
    "\n",
    "# fig.write_html(pathfile + file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graphs_list = [\n",
    "    {\n",
    "    \"name_o_var\": 'Number of adaptations',\n",
    "    \"var\": 'LSS_tot',\n",
    "    \"dataframe\": agents_df,\n",
    "    \"x_axis\": 'period'\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Number of adaptations of Technology producers',\n",
    "    \"var\": 'LSS_tot',\n",
    "    \"dataframe\": agents_df.loc[agents_df['genre'] == 'TP'],\n",
    "    \"x_axis\": 'period'\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Number of adaptations of Energy providers',\n",
    "    \"var\": 'LSS_tot',\n",
    "    \"dataframe\": agents_df.loc[agents_df['genre'] == 'EP'],\n",
    "    \"x_axis\": 'period'\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Full number of adaptations',\n",
    "    \"var\": 'LSS_weak',\n",
    "    \"dataframe\": agents_df,\n",
    "    \"x_axis\": 'period'\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Full number of adaptations of Technology producers',\n",
    "    \"var\": 'LSS_weak',\n",
    "    \"dataframe\": agents_df.loc[agents_df['genre'] == 'TP'],\n",
    "    \"x_axis\": 'period'\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Full number of adaptations of Energy providers',\n",
    "    \"var\": 'LSS_weak',\n",
    "    \"dataframe\": agents_df.loc[agents_df['genre'] == 'EP'],\n",
    "    \"x_axis\": 'period'\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Money',\n",
    "    \"var\": 'wallet',\n",
    "    \"dataframe\": agents_df,\n",
    "    \"x_axis\": 'period'\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Money of Technology producers',\n",
    "    \"var\": 'wallet',\n",
    "    \"dataframe\": agents_df.loc[agents_df['genre'] == 'TP'],\n",
    "    \"x_axis\": 'period'\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Money of Energy providers',\n",
    "    \"var\": 'wallet',\n",
    "    \"dataframe\": agents_df.loc[agents_df['genre'] == 'EP'],\n",
    "    \"x_axis\": 'period'\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Ammount to shareholders',\n",
    "    \"var\": 'shareholder_money',\n",
    "    \"dataframe\": agents_df,\n",
    "    \"x_axis\": 'period'\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Ammount to shareholders of Technology producers',\n",
    "    \"var\": 'shareholder_money',\n",
    "    \"dataframe\": agents_df.loc[agents_df['genre'] == 'TP'],\n",
    "    \"x_axis\": 'period'\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Ammount to shareholders of Energy providers',\n",
    "    \"var\": 'shareholder_money',\n",
    "    \"dataframe\": agents_df.loc[agents_df['genre'] == 'EP'],\n",
    "    \"x_axis\": 'period'\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Investment in capacity of Technology producers',\n",
    "    \"var\": 'capacity',\n",
    "    \"dataframe\": agents_df.loc[agents_df['genre'] == 'TP'],\n",
    "    \"x_axis\": 'period',\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Investment in R&D to shareholders of Technology producers',\n",
    "    \"var\": 'RandD',\n",
    "    \"dataframe\": agents_df.loc[agents_df['genre'] == 'TP'],\n",
    "    \"x_axis\": 'period',\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Remaining demand',\n",
    "    \"var\": 'Remaining_demand',\n",
    "    \"dataframe\": agents_df.loc[agents_df['genre'] == 'DD'],\n",
    "    \"x_axis\": 'period'\n",
    "    },\n",
    "]\n",
    "\n",
    "for graph in graphs_list:\n",
    "    if 'log_y' in graph:\n",
    "        log_y = graph['log_y']\n",
    "    else:\n",
    "        log_y= False\n",
    "    if 'log_x' in graph:\n",
    "        log_x = graph['log_x']\n",
    "    else:\n",
    "        log_x= False\n",
    "    simple_graph(graph['name_o_var'], graph['var'], graph['dataframe'], graph['x_axis'], groupby=None, remove_outliers=True, show=True, log_y=log_y, log_x=log_x)\n",
    "simple_graph('Remaining demand (sum)', 'Remaining_demand', agents_df.loc[agents_df['genre'] == 'DD'], 'period', groupby=None, remove_outliers=True, show=True, _sum=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graphs_list = [\n",
    "    {\n",
    "    \"name_o_var\": 'Avoided emissions',\n",
    "    \"var\": 'avoided_emissions',\n",
    "    \"dataframe\": mix_df,\n",
    "    \"x_axis\": 'period',\n",
    "    \"sum\": True\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Number of lumps',\n",
    "    \"var\": 'Lumps',\n",
    "    \"dataframe\": mix_df,\n",
    "    \"x_axis\": 'period',\n",
    "    \"sum\": True\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Number of lumps of wind',\n",
    "    \"var\": 'Lumps',\n",
    "    \"dataframe\": mix_df.loc[mix_df['source'] == 1],\n",
    "    \"x_axis\": 'period',\n",
    "    \"sum\": True\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Number of lumps of solar',\n",
    "    \"var\": 'Lumps',\n",
    "    \"dataframe\": mix_df.loc[mix_df['source'] == 2],\n",
    "    \"x_axis\": 'period',\n",
    "    \"sum\": True\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Number of lumps of thermal',\n",
    "    \"var\": 'Lumps',\n",
    "    \"dataframe\": mix_df.loc[mix_df['source'] == 0],\n",
    "    \"x_axis\": 'period',\n",
    "    \"sum\": True\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Greeness of the system',\n",
    "    \"var\": 'green',\n",
    "    \"dataframe\": mix_df,\n",
    "    \"x_axis\": 'period',\n",
    "    \"sum\": True\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Price',\n",
    "    \"var\": 'price',\n",
    "    \"dataframe\": mix_df,\n",
    "    \"x_axis\": 'period',\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Electricity produced',\n",
    "    \"var\": 'MWh',\n",
    "    \"dataframe\": mix_df.loc[mix_df['status'] == 'contracted'],\n",
    "    \"x_axis\": 'period',\n",
    "    \"sum\": True\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Electricity produced by solar',\n",
    "    \"var\": 'MWh',\n",
    "    \"dataframe\": mix_df.loc[(mix_df['status'] == 'contracted') & (mix_df['source'] == 1)],\n",
    "    \"x_axis\": 'period',\n",
    "    \"sum\": True\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Electricity produced by wind',\n",
    "    \"var\": 'MWh',\n",
    "    \"dataframe\": mix_df.loc[(mix_df['status'] == 'contracted') & (mix_df['source'] == 2)],\n",
    "    \"x_axis\": 'period',\n",
    "    \"sum\": True\n",
    "    },\n",
    "    {\n",
    "    \"name_o_var\": 'Electricity produced by thermal',\n",
    "    \"var\": 'MWh',\n",
    "    \"dataframe\": mix_df.loc[(mix_df['status'] == 'contracted') & (mix_df['source'] == 0)],\n",
    "    \"x_axis\": 'period',\n",
    "    \"sum\": True\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "for graph in graphs_list:\n",
    "    if 'log_y' in graph:\n",
    "        log_y = graph['log_y']\n",
    "    else:\n",
    "        log_y= False\n",
    "    if 'log_x' in graph:\n",
    "        log_x = graph['log_x']\n",
    "    else:\n",
    "        log_x= False\n",
    "\n",
    "    if 'sum' in graph:\n",
    "        _sum = True\n",
    "    else:\n",
    "        _sum = False\n",
    "    simple_graph(graph['name_o_var'], graph['var'], graph['dataframe'], graph['x_axis'], groupby=None, remove_outliers=True, show=True, log_y=log_y, log_x=log_x, _sum=_sum)\n",
    "\n",
    "    print('DONE')\n",
    "print('All DONE')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#simple_graph('Electricity produced by thermal', 'MWh', mix_df.loc[(mix_df['status'] == 'contracted') & (mix_df['source'] == 0)], 'period', groupby=None, remove_outliers=True, show=True, _sum=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def scatter_graph(full_x, full_y, speed=False, groupby=None, show=True):\n",
    "\n",
    "    if groupby is None:\n",
    "        groupby = 'period'\n",
    "\n",
    "    # dataframe = agents_df  # .loc[agents_df['genre'] == 'TP']\n",
    "\n",
    "    x_var, DF_x, _sum_x = full_x[0], full_x[1], full_x[2]\n",
    "    y_var, DF_y, _sum_y = full_y[0], full_y[1], full_y[2]\n",
    "\n",
    "\n",
    "    DF_x = DF_x.groupby(['period', 'seed'],as_index=False)[x_var].sum() if _sum_x is True else DF_x.groupby(['period', 'seed'],as_index=False)[x_var].mean()\n",
    "    DF_y = DF_y.groupby(['period', 'seed'],as_index=False)[y_var].sum() if _sum_y is True else DF_y.groupby(['period', 'seed'],as_index=False)[y_var].mean()\n",
    "\n",
    "    x =list(DF_x.groupby(groupby, as_index=False).median()[x_var])\n",
    "    y =list(DF_y.groupby(groupby, as_index=False).median()[y_var])\n",
    "\n",
    "    if speed is True:\n",
    "        \"\"\"priv_goal[period] - priv_goal[period - 1]\n",
    "                                 ) / priv_goal[period - 1] if priv_goal[period - 1] > 0 else 1\"\"\"\n",
    "        x= [(x[i] - x[i-1])/x[i-1] if x[i-1] != 0 else 0 for i in range(1,len(x))]\n",
    "        x[0] = 0\n",
    "        y= [(y[i] - y[i-1])/y[i-1] if y[i-1] != 0 else 0 for i in range(1,len(y))]\n",
    "        y[0] = 0\n",
    "\n",
    "    fig = go.Figure(go.Scatter(x = x,\n",
    "                               y = y,\n",
    "                               mode='markers',\n",
    "                               marker=dict(\n",
    "                                   color=list(DF_x.groupby(['period'], as_index=False).max()['period']),\n",
    "                                   colorscale='Viridis',\n",
    "                                   line_width=1,\n",
    "                                   showscale=True)))\n",
    "\n",
    "    fig.update_yaxes(type=\"log\")\n",
    "    fig.update_xaxes(type=\"log\")\n",
    "\n",
    "    title=str(x_var) + \" in relation to \" + str(y_var)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=str(x_var),\n",
    "        yaxis_title=str(y_var),\n",
    "        barmode='overlay',\n",
    "        template=\"simple_white\")\n",
    "\n",
    "    # fig.show()\n",
    "\n",
    "    file_name = title + \".html\"\n",
    "    pathfile='Figures/'\n",
    "\n",
    "    fig.write_html(pathfile + file_name)\n",
    "\n",
    "    return fig.show() if show is True else print(str(file_name) + ' is done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scatter_graph(['LSS_tot',\n",
    "               agents_df.loc[agents_df['genre'] == 'EP'], False],\n",
    "              ['wallet', agents_df.loc[agents_df['genre'] == 'EP'], False],\n",
    "              speed=True,\n",
    "              show=False)\n",
    "\n",
    "scatter_graph(['LSS_tot',\n",
    "               agents_df.loc[agents_df['genre'] == 'EP'], False],\n",
    "              ['wallet', agents_df.loc[agents_df['genre'] == 'EP'], False],\n",
    "              speed=False,\n",
    "              show=False)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}